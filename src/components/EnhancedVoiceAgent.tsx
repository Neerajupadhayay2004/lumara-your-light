import { useState, useEffect, useRef, useCallback } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Mic, MicOff, Volume2, VolumeX, MessageCircle, Sparkles, Globe, Brain, Heart, Waves, Zap } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { LumaraMascot } from './LumaraMascot';
import { useLanguage, Language } from '@/contexts/LanguageContext';
import { supabase } from '@/integrations/supabase/client';

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionInstance extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start: () => void;
  stop: () => void;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onend: (() => void) | null;
  onerror: (() => void) | null;
}

interface EnhancedVoiceAgentProps {
  onMessage?: (message: string, response: string) => void;
}

// Therapeutic responses based on detected emotions
const therapeuticResponses: Record<string, Record<Language, string[]>> = {
  anxious: {
    en: [
      "I can sense you're feeling anxious. Let's try a grounding technique together. Take a deep breath with me.",
      "Anxiety can feel overwhelming. Remember, you've faced difficult moments before and come through. You're stronger than you know.",
      "When anxiety rises, focus on this moment. Name 5 things you can see, 4 you can touch, 3 you can hear. I'm right here with you."
    ],
    hi: [
      "‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§Ü‡§™ ‡§ö‡§ø‡§Ç‡§§‡§ø‡§§ ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§á‡§è ‡§∏‡§æ‡§• ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§ó‡•ç‡§∞‡§æ‡§â‡§Ç‡§°‡§ø‡§Ç‡§ó ‡§§‡§ï‡§®‡•Ä‡§ï ‡§Ü‡§ú‡§º‡§Æ‡§æ‡§è‡§Ç‡•§ ‡§Æ‡•á‡§∞‡•á ‡§∏‡§æ‡§• ‡§ó‡§π‡§∞‡•Ä ‡§∏‡§æ‡§Ç‡§∏ ‡§≤‡•á‡§Ç‡•§",
      "‡§ö‡§ø‡§Ç‡§§‡§æ ‡§≠‡§æ‡§∞‡•Ä ‡§≤‡§ó ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§ ‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡•á‡§Ç, ‡§Ü‡§™‡§®‡•á ‡§™‡§π‡§≤‡•á ‡§≠‡•Ä ‡§ï‡§†‡§ø‡§® ‡§™‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§Æ‡§®‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ã‡§ö ‡§∏‡•á ‡§ú‡§º‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§Æ‡§ú‡§º‡§¨‡•Ç‡§§ ‡§π‡•à‡§Ç‡•§",
      "‡§ú‡§¨ ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§¨‡§¢‡§º‡•á, ‡§á‡§∏ ‡§™‡§≤ ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç‡•§ 5 ‡§ö‡•Ä‡§ú‡§º‡•á‡§Ç ‡§ú‡•ã ‡§Ü‡§™ ‡§¶‡•á‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, 4 ‡§õ‡•Ç ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, 3 ‡§∏‡•Å‡§® ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§Ø‡§π‡•Ä‡§Ç ‡§π‡•Ç‡§Ç‡•§"
    ],
    es: [
      "Puedo sentir que est√°s ansioso. Intentemos una t√©cnica de arraigo juntos. Respira profundo conmigo.",
      "La ansiedad puede ser abrumadora. Recuerda que has enfrentado momentos dif√≠ciles antes. Eres m√°s fuerte de lo que crees.",
      "Cuando la ansiedad aumenta, conc√©ntrate en este momento. Nombra 5 cosas que puedes ver, 4 que puedes tocar, 3 que puedes o√≠r."
    ],
    fr: [
      "Je sens que vous √™tes anxieux. Essayons une technique d'ancrage ensemble. Respirez profond√©ment avec moi.",
      "L'anxi√©t√© peut sembler accablante. N'oubliez pas que vous avez surmont√© des moments difficiles avant. Vous √™tes plus fort que vous ne le pensez.",
      "Quand l'anxi√©t√© monte, concentrez-vous sur ce moment. Nommez 5 choses que vous voyez, 4 que vous touchez, 3 que vous entendez."
    ],
    de: [
      "Ich sp√ºre, dass Sie √§ngstlich sind. Versuchen wir gemeinsam eine Erdungstechnik. Atmen Sie tief mit mir ein.",
      "Angst kann √ºberw√§ltigend sein. Denken Sie daran, Sie haben schwierige Momente zuvor gemeistert. Sie sind st√§rker als Sie denken.",
      "Wenn die Angst steigt, konzentrieren Sie sich auf diesen Moment. Nennen Sie 5 Dinge, die Sie sehen, 4 die Sie ber√ºhren k√∂nnen."
    ]
  },
  sad: {
    en: [
      "I hear the sadness in your voice. It's okay to feel this way. Your feelings are valid and important.",
      "Sadness is a natural part of being human. Allow yourself to feel it. I'm here to listen without judgment.",
      "When you're ready, we can explore what's weighing on your heart. For now, just know you're not alone in this."
    ],
    hi: [
      "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§â‡§¶‡§æ‡§∏‡•Ä ‡§∏‡•Å‡§® ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§ ‡§ê‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§®‡§æ ‡§†‡•Ä‡§ï ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡•Ä ‡§≠‡§æ‡§µ‡§®‡§æ‡§è‡§Ç ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§î‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç‡•§",
      "‡§â‡§¶‡§æ‡§∏‡•Ä ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§π‡•ã‡§®‡•á ‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§π‡•à‡•§ ‡§ñ‡•Å‡§¶ ‡§ï‡•ã ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§®‡•á ‡§¶‡•á‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§ï‡•á ‡§∏‡•Å‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Ç ‡§π‡•Ç‡§Ç‡•§",
      "‡§ú‡§¨ ‡§Ü‡§™ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§Ç, ‡§π‡§Æ ‡§ú‡§æ‡§® ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§≤ ‡§™‡§∞ ‡§ï‡•ç‡§Ø‡§æ ‡§≠‡§æ‡§∞ ‡§π‡•à‡•§ ‡§Ö‡§≠‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ú‡§æ‡§® ‡§≤‡•á‡§Ç ‡§ï‡§ø ‡§Ü‡§™ ‡§Ö‡§ï‡•á‡§≤‡•á ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡§Ç‡•§"
    ],
    es: [
      "Escucho la tristeza en tu voz. Est√° bien sentirse as√≠. Tus sentimientos son v√°lidos e importantes.",
      "La tristeza es una parte natural de ser humano. Perm√≠tete sentirla. Estoy aqu√≠ para escuchar sin juzgar.",
      "Cuando est√©s listo, podemos explorar lo que pesa en tu coraz√≥n. Por ahora, solo s√© que no est√°s solo."
    ],
    fr: [
      "J'entends la tristesse dans votre voix. C'est normal de se sentir ainsi. Vos sentiments sont valides et importants.",
      "La tristesse fait partie de la nature humaine. Permettez-vous de la ressentir. Je suis l√† pour √©couter sans jugement.",
      "Quand vous serez pr√™t, nous pourrons explorer ce qui p√®se sur votre c≈ìur. Pour l'instant, sachez que vous n'√™tes pas seul."
    ],
    de: [
      "Ich h√∂re die Traurigkeit in Ihrer Stimme. Es ist okay, so zu f√ºhlen. Ihre Gef√ºhle sind berechtigt und wichtig.",
      "Traurigkeit ist ein nat√ºrlicher Teil des Menschseins. Erlauben Sie sich, sie zu f√ºhlen. Ich bin hier, um zuzuh√∂ren.",
      "Wenn Sie bereit sind, k√∂nnen wir erkunden, was auf Ihrem Herzen lastet. Wissen Sie, dass Sie nicht allein sind."
    ]
  },
  stressed: {
    en: [
      "It sounds like you're carrying a heavy load. Let's pause and take three slow breaths together.",
      "Stress can make everything feel urgent. But right now, in this moment, you're safe. Let's focus on one thing at a time.",
      "Your body holds onto stress. Try rolling your shoulders and releasing that tension. I'm here to help you find calm."
    ],
    hi: [
      "‡§ê‡§∏‡§æ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§Ü‡§™ ‡§≠‡§æ‡§∞‡•Ä ‡§¨‡•ã‡§ù ‡§â‡§†‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§ö‡§≤‡§ø‡§è ‡§∞‡•Å‡§ï‡•á‡§Ç ‡§î‡§∞ ‡§∏‡§æ‡§• ‡§Æ‡•á‡§Ç ‡§§‡•Ä‡§® ‡§ß‡•Ä‡§Æ‡•Ä ‡§∏‡§æ‡§Ç‡§∏‡•á‡§Ç ‡§≤‡•á‡§Ç‡•§",
      "‡§§‡§®‡§æ‡§µ ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§≠‡•Ä, ‡§á‡§∏ ‡§™‡§≤ ‡§Æ‡•á‡§Ç, ‡§Ü‡§™ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§π‡•à‡§Ç‡•§ ‡§è‡§ï ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§ö‡•Ä‡§ú‡§º ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç‡•§",
      "‡§Ü‡§™‡§ï‡§æ ‡§∂‡§∞‡•Ä‡§∞ ‡§§‡§®‡§æ‡§µ ‡§ï‡•ã ‡§™‡§ï‡§°‡§º‡•á ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§ ‡§Ö‡§™‡§®‡•á ‡§ï‡§Ç‡§ß‡•ã‡§Ç ‡§ï‡•ã ‡§ò‡•Å‡§Æ‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§§‡§®‡§æ‡§µ ‡§õ‡•ã‡§°‡§º‡•á‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§∂‡§æ‡§Ç‡§§‡§ø ‡§ñ‡•ã‡§ú‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•Ç‡§Ç‡•§"
    ],
    es: [
      "Parece que llevas una carga pesada. Hagamos una pausa y tomemos tres respiraciones lentas juntos.",
      "El estr√©s puede hacer que todo parezca urgente. Pero ahora mismo, en este momento, est√°s a salvo.",
      "Tu cuerpo retiene el estr√©s. Intenta rodar los hombros y liberar esa tensi√≥n. Estoy aqu√≠ para ayudarte."
    ],
    fr: [
      "On dirait que vous portez une lourde charge. Faisons une pause et prenons trois respirations lentes ensemble.",
      "Le stress peut tout faire para√Ætre urgent. Mais en ce moment, vous √™tes en s√©curit√©. Concentrons-nous sur une chose √† la fois.",
      "Votre corps retient le stress. Essayez de rouler vos √©paules et de lib√©rer cette tension. Je suis l√† pour vous aider."
    ],
    de: [
      "Es klingt, als tr√ºgen Sie eine schwere Last. Lass uns pausieren und drei langsame Atemz√ºge zusammen nehmen.",
      "Stress kann alles dringend erscheinen lassen. Aber jetzt, in diesem Moment, sind Sie sicher. Konzentrieren wir uns auf eines.",
      "Ihr K√∂rper h√§lt Stress fest. Versuchen Sie, Ihre Schultern zu rollen und die Spannung zu l√∂sen. Ich bin hier, um zu helfen."
    ]
  },
  happy: {
    en: [
      "I can hear the joy in your voice! That's wonderful. Let's celebrate this positive moment together.",
      "Your happiness is contagious! It's beautiful to hear you feeling good. What's bringing you joy today?",
      "This is a beautiful moment. Savoring happiness helps it last longer. I'm so glad you're feeling well!"
    ],
    hi: [
      "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§∏‡•Å‡§® ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç! ‡§Ø‡§π ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ ‡§π‡•à‡•§ ‡§ö‡§≤‡§ø‡§è ‡§á‡§∏ ‡§∏‡§ï‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡§≤ ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§Æ‡§®‡§æ‡§è‡§Ç‡•§",
      "‡§Ü‡§™‡§ï‡•Ä ‡§ñ‡•Å‡§∂‡•Ä ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§æ‡§Æ‡§ï ‡§π‡•à! ‡§Ü‡§™‡§ï‡•ã ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§§‡•á ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à‡•§ ‡§Ü‡§ú ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§ñ‡•Å‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à?",
      "‡§Ø‡§π ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§™‡§≤ ‡§π‡•à‡•§ ‡§ñ‡•Å‡§∂‡•Ä ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§®‡•á ‡§∏‡•á ‡§Ø‡§π ‡§≤‡§Ç‡§¨‡•á ‡§∏‡§Æ‡§Ø ‡§§‡§ï ‡§∞‡§π‡§§‡•Ä ‡§π‡•à‡•§ ‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç!"
    ],
    es: [
      "¬°Puedo escuchar la alegr√≠a en tu voz! Eso es maravilloso. Celebremos este momento positivo juntos.",
      "¬°Tu felicidad es contagiosa! Es hermoso escucharte sentir bien. ¬øQu√© te trae alegr√≠a hoy?",
      "Este es un momento hermoso. Saborear la felicidad la hace durar m√°s. ¬°Me alegra que te sientas bien!"
    ],
    fr: [
      "J'entends la joie dans votre voix! C'est merveilleux. C√©l√©brons ce moment positif ensemble.",
      "Votre bonheur est contagieux! C'est beau de vous entendre vous sentir bien. Qu'est-ce qui vous apporte de la joie?",
      "C'est un beau moment. Savourer le bonheur le fait durer plus longtemps. Je suis ravi que vous vous sentiez bien!"
    ],
    de: [
      "Ich kann die Freude in Ihrer Stimme h√∂ren! Das ist wunderbar. Lass uns diesen positiven Moment zusammen feiern.",
      "Ihre Gl√ºcklichkeit ist ansteckend! Es ist sch√∂n zu h√∂ren, dass Sie sich gut f√ºhlen. Was bringt Ihnen heute Freude?",
      "Das ist ein sch√∂ner Moment. Das Genie√üen von Gl√ºck l√§sst es l√§nger dauern. Ich freue mich, dass es Ihnen gut geht!"
    ]
  },
  default: {
    en: [
      "I'm here to listen. Take your time and share what's on your mind.",
      "Thank you for sharing with me. Your thoughts and feelings matter.",
      "I appreciate you opening up. How can I best support you right now?"
    ],
    hi: [
      "‡§Æ‡•à‡§Ç ‡§∏‡•Å‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Ç ‡§π‡•Ç‡§Ç‡•§ ‡§Ö‡§™‡§®‡§æ ‡§∏‡§Æ‡§Ø ‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•á ‡§Æ‡§® ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§",
      "‡§Æ‡•á‡§∞‡•á ‡§∏‡§æ‡§• ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§ ‡§Ü‡§™‡§ï‡•á ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§î‡§∞ ‡§≠‡§æ‡§µ‡§®‡§æ‡§è‡§Ç ‡§Æ‡§æ‡§Ø‡§®‡•á ‡§∞‡§ñ‡§§‡•Ä ‡§π‡•à‡§Ç‡•§",
      "‡§ñ‡•Å‡§≤‡§ï‡§∞ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§ ‡§Æ‡•à‡§Ç ‡§Ö‡§≠‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡•à‡§∏‡•á ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?"
    ],
    es: [
      "Estoy aqu√≠ para escuchar. T√≥mate tu tiempo y comparte lo que tienes en mente.",
      "Gracias por compartir conmigo. Tus pensamientos y sentimientos importan.",
      "Aprecio que te abras. ¬øC√≥mo puedo apoyarte mejor ahora mismo?"
    ],
    fr: [
      "Je suis l√† pour √©couter. Prenez votre temps et partagez ce que vous avez en t√™te.",
      "Merci de partager avec moi. Vos pens√©es et sentiments comptent.",
      "J'appr√©cie que vous vous ouvriez. Comment puis-je vous soutenir au mieux maintenant?"
    ],
    de: [
      "Ich bin hier, um zuzuh√∂ren. Nehmen Sie sich Zeit und teilen Sie, was Sie besch√§ftigt.",
      "Danke, dass Sie mir mitteilen. Ihre Gedanken und Gef√ºhle sind wichtig.",
      "Ich sch√§tze es, dass Sie sich √∂ffnen. Wie kann ich Sie jetzt am besten unterst√ºtzen?"
    ]
  }
};

// Language to speech recognition language code mapping
const languageToSpeechCode: Record<Language, string> = {
  en: 'en-US',
  hi: 'hi-IN',
  es: 'es-ES',
  fr: 'fr-FR',
  de: 'de-DE'
};

// Voice selection per language
const getVoiceForLanguage = (lang: Language): SpeechSynthesisVoice | null => {
  const voices = speechSynthesis.getVoices();
  const langCode = languageToSpeechCode[lang].split('-')[0];
  
  // Preferred voices for each language
  const preferredVoices: Record<string, string[]> = {
    en: ['Samantha', 'Google UK English Female', 'Microsoft Aria', 'Google US English'],
    hi: ['Google ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä', 'Lekha', 'Microsoft Swara'],
    es: ['Monica', 'Google espa√±ol', 'Microsoft Helena'],
    fr: ['Am√©lie', 'Google fran√ßais', 'Microsoft Julie'],
    de: ['Anna', 'Google Deutsch', 'Microsoft Katja']
  };

  // Try to find preferred voice
  for (const name of preferredVoices[langCode] || []) {
    const voice = voices.find(v => v.name.includes(name));
    if (voice) return voice;
  }

  // Fallback to any voice matching the language
  return voices.find(v => v.lang.startsWith(langCode)) || null;
};

// Emotion detection keywords per language
const emotionKeywords: Record<string, Record<Language, string[]>> = {
  anxious: {
    en: ['anxious', 'worried', 'nervous', 'panic', 'scared', 'fear', 'overwhelmed', 'anxiety'],
    hi: ['‡§ö‡§ø‡§Ç‡§§‡§ø‡§§', '‡§™‡§∞‡•á‡§∂‡§æ‡§®', '‡§°‡§∞', '‡§ò‡§¨‡§∞‡§æ‡§π‡§ü', '‡§≠‡§Ø', '‡§§‡§®‡§æ‡§µ'],
    es: ['ansioso', 'preocupado', 'nervioso', 'p√°nico', 'miedo', 'temor'],
    fr: ['anxieux', 'inquiet', 'nerveux', 'panique', 'peur', 'angoisse'],
    de: ['√§ngstlich', 'besorgt', 'nerv√∂s', 'panik', 'angst', 'furcht']
  },
  sad: {
    en: ['sad', 'depressed', 'down', 'crying', 'unhappy', 'miserable', 'grief', 'lonely'],
    hi: ['‡§â‡§¶‡§æ‡§∏', '‡§¶‡•Å‡§ñ‡•Ä', '‡§∞‡•ã ‡§∞‡§π‡§æ', '‡§Ö‡§ï‡•á‡§≤‡§æ', '‡§®‡§ø‡§∞‡§æ‡§∂', '‡§¶‡§∞‡•ç‡§¶'],
    es: ['triste', 'deprimido', 'llorando', 'infeliz', 'solo', 'dolor'],
    fr: ['triste', 'd√©prim√©', 'pleure', 'malheureux', 'seul', 'chagrin'],
    de: ['traurig', 'deprimiert', 'weinen', 'ungl√ºcklich', 'einsam', 'schmerz']
  },
  stressed: {
    en: ['stressed', 'pressure', 'exhausted', 'burnout', 'tired', 'overwhelmed', 'busy'],
    hi: ['‡§§‡§®‡§æ‡§µ', '‡§•‡§ï‡§æ', '‡§¶‡§¨‡§æ‡§µ', '‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§', '‡§™‡§∞‡•á‡§∂‡§æ‡§®'],
    es: ['estresado', 'presi√≥n', 'agotado', 'cansado', 'ocupado'],
    fr: ['stress√©', 'pression', '√©puis√©', 'fatigu√©', 'd√©bord√©'],
    de: ['gestresst', 'druck', 'ersch√∂pft', 'm√ºde', '√ºberfordert']
  },
  happy: {
    en: ['happy', 'joy', 'excited', 'great', 'wonderful', 'amazing', 'good', 'better'],
    hi: ['‡§ñ‡•Å‡§∂', '‡§ñ‡•Å‡§∂‡•Ä', '‡§Ö‡§ö‡•ç‡§õ‡§æ', '‡§¨‡•á‡§π‡§§‡§∞', '‡§Æ‡§ú‡§º‡§æ'],
    es: ['feliz', 'alegr√≠a', 'emocionado', 'genial', 'maravilloso'],
    fr: ['heureux', 'joie', 'excit√©', 'super', 'merveilleux'],
    de: ['gl√ºcklich', 'freude', 'aufgeregt', 'toll', 'wunderbar']
  }
};

export const EnhancedVoiceAgent = ({ onMessage }: EnhancedVoiceAgentProps) => {
  const { language, t } = useLanguage();
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [currentText, setCurrentText] = useState('');
  const [responseText, setResponseText] = useState('');
  const [detectedEmotion, setDetectedEmotion] = useState<string>('neutral');
  const [conversationHistory, setConversationHistory] = useState<Array<{role: string, content: string}>>([]);
  const [mascotEmotion, setMascotEmotion] = useState<'happy' | 'calm' | 'listening' | 'thinking' | 'speaking' | 'concerned'>('calm');
  const [voicesLoaded, setVoicesLoaded] = useState(false);
  const recognitionRef = useRef<SpeechRecognitionInstance | null>(null);

  // Load voices
  useEffect(() => {
    const loadVoices = () => {
      const voices = speechSynthesis.getVoices();
      if (voices.length > 0) setVoicesLoaded(true);
    };
    loadVoices();
    speechSynthesis.onvoiceschanged = loadVoices;
    return () => { speechSynthesis.onvoiceschanged = null; };
  }, []);

  // Initialize speech recognition
  useEffect(() => {
    const windowWithSpeech = window as Window & { 
      SpeechRecognition?: new () => SpeechRecognitionInstance;
      webkitSpeechRecognition?: new () => SpeechRecognitionInstance;
    };

    if (windowWithSpeech.webkitSpeechRecognition || windowWithSpeech.SpeechRecognition) {
      const SpeechRecognitionClass = windowWithSpeech.SpeechRecognition || windowWithSpeech.webkitSpeechRecognition;
      if (SpeechRecognitionClass) {
        recognitionRef.current = new SpeechRecognitionClass();
        recognitionRef.current.continuous = false;
        recognitionRef.current.interimResults = true;
        recognitionRef.current.lang = languageToSpeechCode[language];
      }
    }

    return () => {
      if (recognitionRef.current) recognitionRef.current.stop();
      speechSynthesis.cancel();
    };
  }, []);

  // Update recognition language when language changes
  useEffect(() => {
    if (recognitionRef.current) {
      recognitionRef.current.lang = languageToSpeechCode[language];
    }
  }, [language]);

  const detectEmotion = useCallback((text: string): string => {
    const lowerText = text.toLowerCase();
    for (const [emotion, keywords] of Object.entries(emotionKeywords)) {
      const langKeywords = keywords[language] || keywords.en;
      if (langKeywords.some(keyword => lowerText.includes(keyword))) {
        return emotion;
      }
    }
    return 'default';
  }, [language]);

  const getAIResponse = useCallback(async (userText: string): Promise<string> => {
    const emotion = detectEmotion(userText);
    setDetectedEmotion(emotion);

    // First, try local therapeutic responses for immediate feedback
    const responses = therapeuticResponses[emotion]?.[language] || therapeuticResponses.default[language];
    const localResponse = responses[Math.floor(Math.random() * responses.length)];

    // Then try to get AI-enhanced response
    try {
      const newHistory = [...conversationHistory, { role: 'user', content: userText }];
      
      const response = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/lumara-chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`
        },
        body: JSON.stringify({
          messages: newHistory.map(m => ({ role: m.role, content: m.content })),
          userMessage: userText
        }),
      });

      if (!response.ok || !response.body) {
        return localResponse;
      }

      // Stream the response
      let aiResponse = '';
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        buffer += decoder.decode(value, { stream: true });
        
        let newlineIdx;
        while ((newlineIdx = buffer.indexOf('\n')) !== -1) {
          const line = buffer.slice(0, newlineIdx).trim();
          buffer = buffer.slice(newlineIdx + 1);
          if (!line.startsWith('data: ') || line === 'data: [DONE]') continue;
          try {
            const parsed = JSON.parse(line.slice(6));
            const delta = parsed.choices?.[0]?.delta?.content;
            if (delta) aiResponse += delta;
          } catch {}
        }
      }

      if (aiResponse) {
        setConversationHistory([...newHistory, { role: 'assistant', content: aiResponse }]);
        return aiResponse;
      }
      return localResponse;
    } catch {
      return localResponse;
    }
  }, [conversationHistory, detectEmotion, language]);

  const speakText = useCallback((text: string) => {
    if (isMuted || !('speechSynthesis' in window)) return;
    
    speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    
    // Get appropriate voice for language
    const voice = getVoiceForLanguage(language);
    if (voice) utterance.voice = voice;
    
    utterance.lang = languageToSpeechCode[language];
    utterance.rate = 0.9;
    utterance.pitch = 1.05;
    utterance.volume = 0.9;
    
    utterance.onstart = () => {
      setIsSpeaking(true);
      setMascotEmotion('speaking');
    };
    
    utterance.onend = () => {
      setIsSpeaking(false);
      setMascotEmotion('calm');
    };
    
    speechSynthesis.speak(utterance);
  }, [isMuted, language]);

  const processUserInput = useCallback(async (text: string) => {
    if (!text.trim()) return;
    
    setIsProcessing(true);
    setMascotEmotion('thinking');
    
    const response = await getAIResponse(text);
    setResponseText(response);
    
    setIsProcessing(false);
    speakText(response);
    
    onMessage?.(text, response);
  }, [getAIResponse, speakText, onMessage]);

  const toggleListening = useCallback(() => {
    if (!recognitionRef.current) return;
    
    if (isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
      setMascotEmotion('thinking');
      
      // Process the captured text
      if (currentText.trim()) {
        processUserInput(currentText);
      }
    } else {
      speechSynthesis.cancel();
      setCurrentText('');
      setResponseText('');
      
      recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {
        const transcript = Array.from(event.results)
          .map(result => result[0].transcript)
          .join('');
        setCurrentText(transcript);
      };
      
      recognitionRef.current.onend = () => {
        setIsListening(false);
        if (currentText.trim()) {
          setMascotEmotion('thinking');
        } else {
          setMascotEmotion('calm');
        }
      };
      
      recognitionRef.current.onerror = () => {
        setIsListening(false);
        setMascotEmotion('concerned');
      };
      
      recognitionRef.current.start();
      setIsListening(true);
      setMascotEmotion('listening');
    }
  }, [isListening, currentText, processUserInput]);

  const getEmotionIcon = () => {
    switch (detectedEmotion) {
      case 'anxious': return <Waves className="w-4 h-4" />;
      case 'sad': return <Heart className="w-4 h-4" />;
      case 'stressed': return <Zap className="w-4 h-4" />;
      case 'happy': return <Sparkles className="w-4 h-4" />;
      default: return <Brain className="w-4 h-4" />;
    }
  };

  const getEmotionColor = () => {
    switch (detectedEmotion) {
      case 'anxious': return 'text-blue-400';
      case 'sad': return 'text-indigo-400';
      case 'stressed': return 'text-amber-400';
      case 'happy': return 'text-green-400';
      default: return 'text-primary';
    }
  };

  return (
    <motion.div 
      initial={{ opacity: 0, y: 20 }} 
      animate={{ opacity: 1, y: 0 }} 
      className="bg-card/60 backdrop-blur-xl rounded-3xl p-6 border border-border/30"
    >
      {/* Header */}
      <div className="flex items-center justify-between mb-6">
        <h3 className="font-display text-lg font-semibold text-gradient-gold flex items-center gap-2">
          <Sparkles className="w-5 h-5" />
          Lumara Voice AI
        </h3>
        <div className="flex items-center gap-2">
          <Globe className="w-4 h-4 text-muted-foreground" />
          <span className="text-xs text-muted-foreground uppercase">{language}</span>
        </div>
      </div>

      {/* Mascot */}
      <div className="flex justify-center mb-6">
        <motion.div
          animate={{
            scale: isListening ? [1, 1.05, 1] : 1,
          }}
          transition={{ duration: 1.5, repeat: isListening ? Infinity : 0 }}
        >
          <LumaraMascot size="xl" emotion={mascotEmotion} />
        </motion.div>
      </div>

      {/* Emotion indicator */}
      <AnimatePresence>
        {detectedEmotion !== 'neutral' && detectedEmotion !== 'default' && (
          <motion.div
            initial={{ opacity: 0, y: -10 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0 }}
            className={`flex items-center justify-center gap-2 mb-4 ${getEmotionColor()}`}
          >
            {getEmotionIcon()}
            <span className="text-sm capitalize">Sensing: {detectedEmotion}</span>
          </motion.div>
        )}
      </AnimatePresence>

      {/* Text display */}
      <div className="space-y-3 mb-6">
        {/* User speech */}
        <motion.div 
          className="bg-muted/30 rounded-2xl p-4 min-h-[60px] flex items-center justify-center"
          animate={{ borderColor: isListening ? 'hsl(var(--primary))' : 'transparent' }}
          style={{ borderWidth: 2 }}
        >
          <AnimatePresence mode="wait">
            {currentText ? (
              <motion.p 
                key="text" 
                initial={{ opacity: 0 }} 
                animate={{ opacity: 1 }}
                className="text-center text-sm"
              >
                {currentText}
              </motion.p>
            ) : (
              <motion.p 
                key="placeholder"
                className="text-center text-sm text-muted-foreground"
              >
                {isListening ? 'üé§ Listening...' : isProcessing ? 'üß† Processing...' : 'Tap the mic to speak'}
              </motion.p>
            )}
          </AnimatePresence>
        </motion.div>

        {/* AI response */}
        <AnimatePresence>
          {responseText && (
            <motion.div
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0 }}
              className="bg-primary/10 border border-primary/20 rounded-2xl p-4"
            >
              <p className="text-sm leading-relaxed">{responseText}</p>
            </motion.div>
          )}
        </AnimatePresence>
      </div>

      {/* Controls */}
      <div className="flex items-center justify-center gap-4">
        <Button 
          variant="ghost" 
          size="icon" 
          onClick={() => setIsMuted(!isMuted)}
          className="rounded-full"
        >
          {isMuted ? <VolumeX className="w-5 h-5" /> : <Volume2 className="w-5 h-5" />}
        </Button>
        
        <motion.button
          onClick={toggleListening}
          disabled={isProcessing}
          whileTap={{ scale: 0.95 }}
          whileHover={{ scale: 1.05 }}
          className={`
            w-20 h-20 rounded-full flex items-center justify-center shadow-lg
            transition-all duration-300
            ${isListening 
              ? 'bg-red-500 shadow-red-500/30' 
              : isProcessing
                ? 'bg-amber-500 shadow-amber-500/30'
                : 'bg-gradient-to-br from-primary to-primary-glow shadow-primary/30'
            }
          `}
        >
          {isListening ? (
            <MicOff className="w-8 h-8 text-white" />
          ) : isProcessing ? (
            <motion.div
              animate={{ rotate: 360 }}
              transition={{ duration: 1, repeat: Infinity, ease: 'linear' }}
            >
              <Brain className="w-8 h-8 text-white" />
            </motion.div>
          ) : (
            <Mic className="w-8 h-8 text-white" />
          )}
        </motion.button>
        
        <Button 
          variant="ghost" 
          size="icon"
          onClick={() => {
            const responses = therapeuticResponses.default[language];
            const text = responses[Math.floor(Math.random() * responses.length)];
            setResponseText(text);
            speakText(text);
          }}
          className="rounded-full"
        >
          <MessageCircle className="w-5 h-5" />
        </Button>
      </div>

      {/* Listening indicator */}
      <AnimatePresence>
        {isListening && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            className="mt-6 flex justify-center gap-1"
          >
            {[0, 1, 2, 3, 4].map((i) => (
              <motion.div
                key={i}
                className="w-1 bg-primary rounded-full"
                animate={{
                  height: [12, 24, 12],
                }}
                transition={{
                  duration: 0.5,
                  repeat: Infinity,
                  delay: i * 0.1,
                }}
              />
            ))}
          </motion.div>
        )}
      </AnimatePresence>

      <p className="text-xs text-muted-foreground mt-4 text-center">
        üíõ I'm here to listen. Your feelings matter.
      </p>
    </motion.div>
  );
};
